{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Embedding\n",
    "\n",
    "This notebook uses [`jina-embeddings-v2-base-en` embedding model](https://huggingface.co/jinaai/jina-embeddings-v2-base-en) to transform abstract texts to a 768-dimensional embedding space.\n",
    "\n",
    "> **Note from our 2021 study:** In 2021, we used GPT-3 Embedding API to generate text similarity embeddings from the input text. Since the API was limited to pieces with less than 2048 token, we used heuristics to remove long abstracts with more than 2048 tokens. Note that, starting January 2022, GPT-3 Embedding API is NOT free anymore. You probably need to pay for it to run this notebook. Cached results from 2021 are available on HuggingFace.\n",
    "\n",
    "## Input\n",
    "- `data/pubmed/abstracts_2023.csv.gz` contains raw un-preprocessed texts collected from PubMed. To speed things up, duplicate documents will be queried only once. Documents with identical PMID are considered as duplicate.\n",
    "\n",
    "## Outputs\n",
    "\n",
    "- `models/embeddings/jina-embeddings-v2-base-en.safetensors`, in SafeTesnsors format, contains the PMIDs and corresponding embedding weights; one key per document.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "You may need a valid HuggingFace access token to run this notebook. You can get one from [here](https://huggingface.co/settings/tokens).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "import polars as pl\n",
    "import torch\n",
    "from safetensors.torch import save_file, load_file\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from src.cogtext.datasets.pubmed import PubMedDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "GPT3_MODEL_ID = 'ada'  # 1024-dim embeddings\n",
    "HF_MODEL_NAME = 'jinaai/jina-embeddings-v2-small-en'\n",
    "\n",
    "OUTPUT_FILE = f'data/embeddings/abstracts_2023_{HF_MODEL_NAME.split(\"/\")[1]}-sbert.safetensors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare and cleanup the input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique documents: 464765\n"
     ]
    }
   ],
   "source": [
    "data = PubMedDataset(year=2023).load()\n",
    "data = data.unique('pmid')\n",
    "\n",
    "print(f'Number of unique documents: {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3168 existing embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1485260dc4294f0bb398e8cf8385e979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/461597 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 1. Parameters\n",
    "batch_size = 8          # number of abstracts to embed at once\n",
    "n_embedded = 0          # number of embedded abstracts\n",
    "existing_pmids = []     # list of existing embedded pmids\n",
    "cache_dir = Path('tmp/embeddings') / HF_MODEL_NAME.split(\"/\")[1]\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. load existing cached embeddings\n",
    "for f in cache_dir.glob('*.safetensors'):\n",
    "  embeddings = load_file(f)\n",
    "  pmids = [int(k) for k in embeddings.keys()]\n",
    "  existing_pmids.extend(pmids)\n",
    "\n",
    "data = data.filter(~pl.col('pmid').is_in(existing_pmids))\n",
    "print(f'Loaded {len(existing_pmids)} existing embeddings.')\n",
    "\n",
    "# 3. initialize the pipeline\n",
    "model = SentenceTransformer(HF_MODEL_NAME, device='cuda').eval()\n",
    "model.max_seq_length = 2048\n",
    "\n",
    "# 4. embed texts\n",
    "with torch.no_grad():\n",
    "  with tqdm(total=len(data)) as pbar:\n",
    "    while n_embedded < len(data):\n",
    "      batch = data.slice(n_embedded, batch_size)\n",
    "      texts = batch['abstract'].to_list()\n",
    "      pmids = batch.select(pl.col('pmid').cast(pl.Utf8))['pmid'].to_list()\n",
    "      e = model.encode(texts, convert_to_tensor=True)\n",
    "      e = dict(zip(pmids, e))\n",
    "      save_file(e, cache_dir / f'from_{pmids[0]}.safetensors')  \n",
    "      n_embedded += batch_size\n",
    "      pbar.update(batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogtext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c6d8e22829943183dd37d6e0ea17534c0ca1a31e180ed9f59e3b2e78d2c52b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
