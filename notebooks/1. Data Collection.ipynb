{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ea20dcc4936bc3e336221d5e5ae7bcd09719da9b70640ea666426cf2d919dc3d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    }
   ],
   "source": [
    "from rdflib import OWL, Graph\n",
    "from rdflib.namespace import RDFS\n",
    "from owlready2 import get_ontology, default_world\n",
    "import xmltodict\n",
    "import time\n",
    "from rdflib import URIRef\n",
    "import random\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "\n",
    "# one liner to import cogtext package from `../python` folder.\n",
    "if '../python' not in sys.path: sys.path.append('../python'); from cogtext import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "owl_file = \"../data/ontologies/efo.owl\"\n",
    "owl_prefix = \"http://www.semanticweb.org/morteza/ontologies/2019/11/executive-functions-ontology#\"\n",
    "\n",
    "ONTOLOGY = get_ontology(owl_file).load()\n",
    "GRAPH = default_world.as_rdflib_graph()\n",
    "\n",
    "def query(graph, parent_cls='Task'):\n",
    "    \"\"\"Function to query tasks, constructs, regions, etc.\n",
    "\n",
    "    ## Returns\n",
    "    A list of labels\n",
    "    \"\"\"\n",
    "\n",
    "    cls_name = parent_cls[1:] if parent_cls.startswith(\":\") else parent_cls\n",
    "\n",
    "    query = f\"\"\"\n",
    "    prefix : <{owl_prefix}>\n",
    "\n",
    "    SELECT ?label ?pubmed_query\n",
    "    WHERE {{\n",
    "    ?task rdfs:subClassOf* :{cls_name};\n",
    "          :pubmedQuery ?pubmed_query;\n",
    "          rdfs:label ?label\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # select the all rdfs:labels, flatten the list of labels, and convert them to python string\n",
    "    labels = [labels for labels in graph.query(query)]\n",
    "    pubmed_queries = {l[0].toPython(): l[1].toPython() for l in labels}\n",
    "    return pubmed_queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "106 tasks found in the EF ontology (baggetta2016)\n"
     ]
    }
   ],
   "source": [
    "pubmed_queries = query(GRAPH, 'BaggettaTask')   # dictionary of task_name -> pubmed_query\n",
    "\n",
    "print(f'{len(pubmed_queries)} tasks found in the EF ontology (baggetta2016)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pybliometrics.scopus import ScopusSearch\n",
    "# s = ScopusSearch('Digit Span')\n",
    "# print(s)\n",
    "# fetch = PubMedFetcher(cachedir='../data/cache/pubmed/')"
   ]
  },
  {
   "source": [
    "# search and cache hits\n",
    "\n",
    "Let's search PubMed for each task query (`ef:pubmedQuery`), then cleanup the XML results into a CSV with the following columns: abstract, title, and a reference to the metadata (pmid).\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[XML2CSV] converting \"Analogy Making Task\" dataset...\n",
      "[XML2CSV] converting \"Animal Shifting\" dataset...\n",
      "[XML2CSV] converting \"Anti-Saccade Task\" dataset...\n",
      "[XML2CSV] converting \"ANT (Attention Network Test)\" dataset...\n",
      "[XML2CSV] converting \"Auditory Attention\" dataset...\n",
      "[XML2CSV] converting \"AOSpan (Automated Operation Span Task)\" dataset...\n",
      "[XML2CSV] converting \"Backward Span Task\" dataset...\n",
      "[XML2CSV] converting \"Backward Color Recall Task\" dataset...\n",
      "[XML2CSV] converting \"Balance Beam Task\" dataset...\n",
      "[XML2CSV] converting \"Bear/Aligator Task\" dataset...\n",
      "[XML2CSV] converting \"Block Design Subtest\" dataset...\n",
      "[XML2CSV] converting \"Block Span\" dataset...\n",
      "[XML2CSV] converting \"Box Crossing Dual Task\" dataset...\n",
      "[XML2CSV] converting \"Boxes Task\" dataset...\n",
      "[XML2CSV] converting \"CATT (Controlled Attention Task)\" dataset...\n",
      "[XML2CSV] converting \"CNT (Contingency Naming Task)\" dataset...\n",
      "[XML2CSV] converting \"CPT (Continuous Performance Task)\" dataset...\n",
      "[XML2CSV] converting \"Category Fluency\" dataset...\n",
      "[XML2CSV] converting \"Category Switch Task\" dataset...\n",
      "[XML2CSV] converting \"Cognitive Flexibility Task\" dataset...\n",
      "[XML2CSV] converting \"Color Shape Task\" dataset...\n",
      "[XML2CSV] converting \"Corsi-block Span\" dataset...\n",
      "[XML2CSV] converting \"Counting Recall\" dataset...\n",
      "[XML2CSV] converting \"Counting Span Task\" dataset...\n",
      "[XML2CSV] converting \"Cued Unpredictable Switch Task\" dataset...\n",
      "[XML2CSV] converting \"D2 Target Detection\" dataset...\n",
      "[XML2CSV] converting \"Degraded Vigilance\" dataset...\n",
      "[XML2CSV] converting \"Delay Choice\" dataset...\n",
      "[XML2CSV] converting \"Delayed Discounting Task\" dataset...\n",
      "[XML2CSV] converting \"Delayed Alteration Task\" dataset...\n",
      "[XML2CSV] converting \"Digit Shifting Task\" dataset...\n",
      "[XML2CSV] converting \"Digit Span\" dataset...\n",
      "[XML2CSV] converting \"Dimension Switching Task\" dataset...\n",
      "[XML2CSV] converting \"DCCS (Dimentional Change Card Sort)\" dataset...\n",
      "[XML2CSV] converting \"Expressive Attention Task\" dataset...\n",
      "[XML2CSV] converting \"FIST (Flexible Item Selection Task)\" dataset...\n",
      "[XML2CSV] converting \"Flanker Task\" dataset...\n",
      "[XML2CSV] converting \"Flexibility Test\" dataset...\n",
      "[XML2CSV] converting \"Gift Delay\" dataset...\n",
      "[XML2CSV] converting \"Gift Wrap\" dataset...\n",
      "[XML2CSV] converting \"Go/NoGo (Digit, Figure)\" dataset...\n",
      "[XML2CSV] converting \"Hayling Test\" dataset...\n",
      "[XML2CSV] converting \"Head-Toes-Knees-Shoulders Tasks\" dataset...\n",
      "[XML2CSV] converting \"IGT (Iowa Gambling Task)\" dataset...\n",
      "[XML2CSV] converting \"Incompatibility Test\" dataset...\n",
      "[XML2CSV] converting \"Keep Track Task\" dataset...\n",
      "[XML2CSV] converting \"Knock and Tap\" dataset...\n",
      "[XML2CSV] converting \"LFT (Lexical Fluency Test)\" dataset...\n",
      "[XML2CSV] converting \"LMT (Letter Memory Task)\" dataset...\n",
      "[XML2CSV] converting \"LNS (Letter Number Sequencing)\" dataset...\n",
      "[XML2CSV] converting \"Letter Fluency\" dataset...\n",
      "[XML2CSV] converting \"Letter Monitoring\" dataset...\n",
      "[XML2CSV] converting \"Listening Recall Task\" dataset...\n",
      "[XML2CSV] converting \"Luria Hand Game\" dataset...\n",
      "[XML2CSV] converting \"MCST (Modified Card Sorting Test)\" dataset...\n",
      "[XML2CSV] converting \"MONITOR\" dataset...\n",
      "[XML2CSV] converting \"Matrix Monitoring Task\" dataset...\n",
      "[XML2CSV] converting \"Mental Counting Task\" dataset...\n",
      "[XML2CSV] converting \"Mister X Task\" dataset...\n",
      "[XML2CSV] converting \"N-back\" dataset...\n",
      "[XML2CSV] converting \"Nebraska Barnyard\" dataset...\n",
      "[XML2CSV] converting \"Nine Boxes\" dataset...\n",
      "[XML2CSV] converting \"Number-Letter Task\" dataset...\n",
      "[XML2CSV] converting \"OSpan (Operating Span)\" dataset...\n",
      "[XML2CSV] converting \"Object Substitution Task\" dataset...\n",
      "[XML2CSV] converting \"Odd One Out\" dataset...\n",
      "[XML2CSV] converting \"Oddity Switching Task\" dataset...\n",
      "[XML2CSV] converting \"PEG (Pencil Tapping Task)\" dataset...\n",
      "[XML2CSV] converting \"PTP (Pick the Picture Game)\" dataset...\n",
      "[XML2CSV] converting \"PVT (Psychomotor Vigilance Task)\" dataset...\n",
      "[XML2CSV] converting \"Pictorial Updating Task\" dataset...\n",
      "[XML2CSV] converting \"Picture-Symbol Task\" dataset...\n",
      "[XML2CSV] converting \"Plus-Minus Task\" dataset...\n",
      "[XML2CSV] converting \"RLG (Random Letter Generation Task)\" dataset...\n",
      "[XML2CSV] converting \"RNG (Random Number Generation Task)\" dataset...\n",
      "[XML2CSV] converting \"Reading Span Task\" dataset...\n",
      "[XML2CSV] converting \"Reversal Learning\" dataset...\n",
      "[XML2CSV] converting \"Reverse Categorization\" dataset...\n",
      "[XML2CSV] converting \"Rspan (Running Span)\" dataset...\n",
      "[XML2CSV] converting \"S-R Compatibility Task\" dataset...\n",
      "[XML2CSV] converting \"SCA (Spatial Conflict Arrows)\" dataset...\n",
      "[XML2CSV] converting \"Self Control Schedule\" dataset...\n",
      "[XML2CSV] converting \"SSS (Serial Subtraction of Sevens)\" dataset...\n",
      "[XML2CSV] converting \"STOP\" dataset...\n",
      "[XML2CSV] converting \"Semantic Fluency Test\" dataset...\n",
      "[XML2CSV] converting \"Sentence Repetition Task\" dataset...\n",
      "[XML2CSV] converting \"Sentence Completion Task\" dataset...\n",
      "[XML2CSV] converting \"Shape School\" dataset...\n",
      "[XML2CSV] converting \"Simon Says\" dataset...\n",
      "[XML2CSV] converting \"Simon Task\" dataset...\n",
      "[XML2CSV] converting \"Snack Delay\" dataset...\n",
      "[XML2CSV] converting \"Sorting Task\" dataset...\n",
      "[XML2CSV] converting \"Span Tasks (Verbal, Arithmetic, Visuospatial)\" dataset...\n",
      "[XML2CSV] converting \"Spin the Pots\" dataset...\n",
      "[XML2CSV] converting \"Stop-Signal Task\" dataset...\n",
      "[XML2CSV] converting \"Stroop\" dataset...\n",
      "[XML2CSV] converting \"TMT (Trail Making Test)\" dataset...\n",
      "[XML2CSV] converting \"Tower of Hanoi\" dataset...\n",
      "[XML2CSV] converting \"Tower of London\" dataset...\n",
      "[XML2CSV] converting \"Toy Sort\" dataset...\n",
      "[XML2CSV] converting \"Verbal Fluency Task\" dataset...\n",
      "[XML2CSV] converting \"Visual Matrix Span Task\" dataset...\n",
      "[XML2CSV] converting \"WCST (Wisconsin Card Sort Test)\" dataset...\n",
      "[XML2CSV] converting \"Local-Global Task\" dataset...\n",
      "[XML2CSV] converting \"More-Less/Even-Odd Task\" dataset...\n",
      "[XML2CSV] converting \"STS (Something's the Same Game)\" dataset...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for task_label, pubmed_query in pubmed_queries.items():\n",
    "    task_label = task_label.replace('/','') \n",
    "    fname = Path('../data/cache') / (task_label + '.xml')\n",
    "\n",
    "    if not fname.exists():\n",
    "        search_and_store(pubmed_query, fname)\n",
    "\n",
    "\n",
    "def find_mesh(mesh_list):\n",
    "    \"\"\"Extracts MeSH names from a list of XML MedlineCitation.MeshHeadingList.MeshHeading tags.\"\"\"\n",
    "    if not isinstance(mesh_list, list):\n",
    "        return []\n",
    "\n",
    "    mesh_names = [h['DescriptorName']['#text'] for h in mesh_list]# if d['DescriptorName']['@MajorTopicYN'] == 'Y']\n",
    "    return mesh_names\n",
    "\n",
    "\n",
    "# now cleanup and convert all abstracts into CSV files\n",
    "for task_label in pubmed_queries.keys():\n",
    "    print(f'[XML2CSV] converting \"{task_label}\" dataset...')\n",
    "\n",
    "    task_label = task_label.replace('/','')\n",
    "\n",
    "    xml_file = Path('../data/cache') / (task_label + '.xml')\n",
    "    csv_file = Path('../data/pubmed') / (task_label + '.csv')\n",
    "\n",
    "    with open(xml_file, 'r') as f:\n",
    "        xml_content = xmltodict.parse(f.read())\n",
    "        if 'PubmedArticleSet' in xml_content:\n",
    "\n",
    "            df = pd.json_normalize(xml_content['PubmedArticleSet']['PubmedArticle'])\n",
    "\n",
    "            # pmid, title, and abstract\n",
    "            df['pmid'] = df['MedlineCitation.PMID.#text']\n",
    "            df['title'] = df['MedlineCitation.Article.ArticleTitle']\n",
    "            df['abstract'] = df['MedlineCitation.Article.Abstract.AbstractText'].apply(cleanup_abstract)\n",
    "            \n",
    "            # publication year\n",
    "            df['year'] = df['MedlineCitation.Article.Journal.JournalIssue.PubDate.Year']\n",
    "\n",
    "            # MeSh topics (some datasets do not contain MeshHeading, e.g., Spin The Pots)\n",
    "            if 'MedlineCitation.MeshHeadingList.MeshHeading' in df.columns:\n",
    "                df['mesh'] = df['MedlineCitation.MeshHeadingList.MeshHeading'].apply(find_mesh)\n",
    "            else:\n",
    "                df['mesh'] = None\n",
    "\n",
    "            # fill missing abstracts with #text value\n",
    "            if 'MedlineCitation.Article.Abstract.AbstractText.#text' in df.columns:\n",
    "                df['abstract'].fillna(df['MedlineCitation.Article.Abstract.AbstractText.#text'], inplace=True)\n",
    "\n",
    "            if 'MedlineCitation.Article.ArticleTitle.#text' in df.columns:\n",
    "                df['title'].fillna(df['MedlineCitation.Article.ArticleTitle.#text'], inplace=True)\n",
    "\n",
    "            df[['pmid', 'year', 'title','abstract', 'mesh']].to_csv(csv_file, index=False)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "source": [
    "## Data cleansing\n",
    "\n",
    "Here, we aim to preprocess PubMed corpora and keep only those relevant metadata. Outputs of this pipeline are stored in the `data/pubmed` folder as csv files; one csv per task corpus.\n",
    "\n",
    "The following metadata will be stored in the processed csv files:\n",
    "\n",
    "- pmid: unique PubMed identifier of the article.\n",
    "- title: escaped title in string format.\n",
    "- abstract: escaped and cleanedup abstract in string format.\n",
    "- year: publication year in YYYY format.\n",
    "- mesh: A list of Medical Subject Headings which contains the field of research and other topics. We only keep major topics."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}