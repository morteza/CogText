{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["%reload_ext autoreload\n","%autoreload 2\n","\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, explained_variance_score, r2_score\n","\n","from tqdm import tqdm\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","from torch.utils.tensorboard import SummaryWriter\n","\n","from skorch import NeuralNetRegressor\n","from skorch.callbacks import TensorBoard\n","\n","from python.cogtext.utils import select_relevant_journals\n","from python.cogtext import co_occurrence_matrix\n","\n","sns.set()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# parameters\n","DEV_MODE = True\n","INPUT_FILE = 'data/pubmed/abstracts.csv.gz'"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# prepare data\n","\n","PUBMED = (pd.read_csv(INPUT_FILE)\n","            .pipe(select_relevant_journals)\n","            .dropna(subset=['abstract']))\n","\n","# only corpora with # of articles < DEV_MAX_CORPUS_SIZE\n","# labels_cnt = PUBMED['label'].value_counts()\n","# small_sets = labels_cnt[labels_cnt < DEV_MAX_CORPUS_SIZE].index.to_list()\n","# PUBMED = PUBMED.query('label in @small_sets',).copy()\n","\n","# DROP tasks/constructs with less than 5 articles (1/test + 1/valid + 4/train = 6)\n","valid_labels = PUBMED['label'].value_counts()[lambda cnt: cnt > 5].index.to_list()\n","PUBMED = PUBMED.query('label in @valid_labels')\n","\n","# train/test split (80% train 20% test)\n","PUBMED_train, PUBMED_test = train_test_split(\n","    PUBMED,\n","    test_size=0.2,\n","    stratify=PUBMED['label'],\n","    random_state=0)\n","\n","n_constructs = PUBMED.groupby('category')['label'].nunique()['CognitiveConstruct']\n","n_tasks = PUBMED.groupby('category')['label'].nunique()['CognitiveTask']"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class MFNet(nn.Module):\n","  def __init__(self, n_tasks, n_constructs, n_embeddings):\n","    super(MFNet, self).__init__()\n","    self.task_embeddings = nn.Embedding(n_tasks, n_embeddings)\n","    self.construct_embeddings = nn.Embedding(n_constructs, n_embeddings)\n","    self.task_biases = torch.nn.Embedding(n_tasks, 1)\n","    self.construct_biases = torch.nn.Embedding(n_constructs, 1)\n","    self.decoder = nn.Linear(n_embeddings, 1)\n","\n","  def forward(self, x):\n","    construct, task = x[:, 0], x[:, 1]\n","    M = self.task_embeddings(task)\n","    C = self.construct_embeddings(construct)\n","    bias = self.task_biases(task) + self.construct_biases(construct)\n","    y = torch.diagonal(M @ C.T).unsqueeze(1) + bias\n","    # y = self.decoder(H)\n","    return y\n","\n","  def fit(self,\n","      X, y,\n","      train_split_size=.8,\n","      n_epochs=1000,\n","      batch_size=100,\n","      logger: SummaryWriter=SummaryWriter()):\n","\n","    assert 0. < train_split_size < 1.0\n","\n","    n_samples = X.shape[0]\n","\n","    train_size = int(n_samples * train_split_size)\n","    test_size = n_samples - train_size\n","\n","\n","    dataset = TensorDataset(X, y)\n","    train_subset, test_subset = random_split(dataset, lengths=(train_size,test_size))\n","\n","    X_test, y_test = dataset[test_subset.indices]\n","\n","    criterion = nn.MSELoss()\n","    optimizer = torch.optim.Adam(self.parameters(), lr=.001)\n","\n","    logger.add_graph(self, [X[:, 0], X[:, 1]])\n","\n","    for epoch in tqdm(range(n_epochs)):\n","\n","      # train model\n","      self.train()\n","      for X_batch, y_batch in DataLoader(train_subset, batch_size=batch_size):\n","        self.zero_grad()\n","\n","        y_pred = self(X_batch)\n","        loss = criterion(y_batch, y_pred)\n","        logger.add_scalar('loss/train', loss.detach(), epoch)\n","        loss.backward()\n","        optimizer.step()\n","\n","      # eval mode\n","      self.eval()\n","      with torch.no_grad():\n","        y_pred = self(X_test)\n","        loss = criterion(y_test, y_pred)\n","        logger.add_scalar('loss/test', loss.detach(), epoch)\n","        \n","        # ev = explained_variance_score(y_test, y_pred)\n","        # logger.add_scalar('explained_variance/test', ev, epoch)\n","\n","    return self"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  epoch    train_loss    valid_loss     dur\n","-------  ------------  ------------  ------\n","      1        \u001b[36m8.0981\u001b[0m        \u001b[32m8.5962\u001b[0m  0.1922\n","      2        \u001b[36m5.4807\u001b[0m        \u001b[32m7.6374\u001b[0m  0.1165\n","      3        \u001b[36m3.9541\u001b[0m        \u001b[32m6.9579\u001b[0m  0.1216\n","      4        \u001b[36m2.9701\u001b[0m        \u001b[32m6.4529\u001b[0m  0.1171\n","      5        \u001b[36m2.2922\u001b[0m        \u001b[32m6.0639\u001b[0m  0.1309\n","      6        \u001b[36m1.8065\u001b[0m        \u001b[32m5.7578\u001b[0m  0.1274\n","      7        \u001b[36m1.4453\u001b[0m        \u001b[32m5.5125\u001b[0m  0.1133\n","      8        \u001b[36m1.1715\u001b[0m        \u001b[32m5.3124\u001b[0m  0.1133\n","      9        \u001b[36m0.9595\u001b[0m        \u001b[32m5.1481\u001b[0m  0.1156\n","     10        \u001b[36m0.7932\u001b[0m        \u001b[32m5.0115\u001b[0m  0.1132\n","     11        \u001b[36m0.6614\u001b[0m        \u001b[32m4.8968\u001b[0m  0.1718\n","     12        \u001b[36m0.5556\u001b[0m        \u001b[32m4.7998\u001b[0m  0.1648\n","     13        \u001b[36m0.4699\u001b[0m        \u001b[32m4.7177\u001b[0m  0.1634\n","     14        \u001b[36m0.4000\u001b[0m        \u001b[32m4.6474\u001b[0m  0.1308\n","     15        \u001b[36m0.3426\u001b[0m        \u001b[32m4.5870\u001b[0m  0.1078\n","     16        \u001b[36m0.2951\u001b[0m        \u001b[32m4.5348\u001b[0m  0.0994\n","     17        \u001b[36m0.2555\u001b[0m        \u001b[32m4.4891\u001b[0m  0.0942\n","     18        \u001b[36m0.2225\u001b[0m        \u001b[32m4.4492\u001b[0m  0.0980\n","     19        \u001b[36m0.1947\u001b[0m        \u001b[32m4.4143\u001b[0m  0.0958\n","     20        \u001b[36m0.1712\u001b[0m        \u001b[32m4.3837\u001b[0m  0.0973\n","     21        \u001b[36m0.1511\u001b[0m        \u001b[32m4.3565\u001b[0m  0.1005\n","     22        \u001b[36m0.1341\u001b[0m        \u001b[32m4.3324\u001b[0m  0.0955\n","     23        \u001b[36m0.1195\u001b[0m        \u001b[32m4.3107\u001b[0m  0.0965\n","     24        \u001b[36m0.1068\u001b[0m        \u001b[32m4.2915\u001b[0m  0.1001\n","     25        \u001b[36m0.0959\u001b[0m        \u001b[32m4.2741\u001b[0m  0.1080\n","     26        \u001b[36m0.0864\u001b[0m        \u001b[32m4.2585\u001b[0m  0.1032\n","     27        \u001b[36m0.0781\u001b[0m        \u001b[32m4.2444\u001b[0m  0.0972\n","     28        \u001b[36m0.0709\u001b[0m        \u001b[32m4.2316\u001b[0m  0.0992\n","     29        \u001b[36m0.0645\u001b[0m        \u001b[32m4.2198\u001b[0m  0.0915\n","     30        \u001b[36m0.0589\u001b[0m        \u001b[32m4.2092\u001b[0m  0.0923\n","     31        \u001b[36m0.0539\u001b[0m        \u001b[32m4.1995\u001b[0m  0.0912\n","     32        \u001b[36m0.0494\u001b[0m        \u001b[32m4.1905\u001b[0m  0.0880\n","     33        \u001b[36m0.0455\u001b[0m        \u001b[32m4.1824\u001b[0m  0.1252\n","     34        \u001b[36m0.0419\u001b[0m        \u001b[32m4.1748\u001b[0m  0.1679\n","     35        \u001b[36m0.0387\u001b[0m        \u001b[32m4.1679\u001b[0m  0.1508\n","     36        \u001b[36m0.0359\u001b[0m        \u001b[32m4.1614\u001b[0m  0.1095\n","     37        \u001b[36m0.0332\u001b[0m        \u001b[32m4.1555\u001b[0m  0.0938\n","     38        \u001b[36m0.0309\u001b[0m        \u001b[32m4.1499\u001b[0m  0.0901\n","     39        \u001b[36m0.0288\u001b[0m        \u001b[32m4.1448\u001b[0m  0.0923\n","     40        \u001b[36m0.0268\u001b[0m        \u001b[32m4.1400\u001b[0m  0.0877\n","     41        \u001b[36m0.0250\u001b[0m        \u001b[32m4.1355\u001b[0m  0.0890\n","     42        \u001b[36m0.0234\u001b[0m        \u001b[32m4.1314\u001b[0m  0.0912\n","     43        \u001b[36m0.0219\u001b[0m        \u001b[32m4.1275\u001b[0m  0.0884\n","     44        \u001b[36m0.0205\u001b[0m        \u001b[32m4.1238\u001b[0m  0.0910\n","     45        \u001b[36m0.0193\u001b[0m        \u001b[32m4.1204\u001b[0m  0.0871\n","     46        \u001b[36m0.0181\u001b[0m        \u001b[32m4.1172\u001b[0m  0.0877\n","     47        \u001b[36m0.0170\u001b[0m        \u001b[32m4.1142\u001b[0m  0.0896\n","     48        \u001b[36m0.0160\u001b[0m        \u001b[32m4.1114\u001b[0m  0.0908\n","     49        \u001b[36m0.0151\u001b[0m        \u001b[32m4.1087\u001b[0m  0.0890\n","     50        \u001b[36m0.0143\u001b[0m        \u001b[32m4.1063\u001b[0m  0.0866\n","     51        \u001b[36m0.0135\u001b[0m        \u001b[32m4.1039\u001b[0m  0.0905\n","     52        \u001b[36m0.0127\u001b[0m        \u001b[32m4.1017\u001b[0m  0.0932\n","     53        \u001b[36m0.0120\u001b[0m        \u001b[32m4.0996\u001b[0m  0.0883\n","     54        \u001b[36m0.0114\u001b[0m        \u001b[32m4.0976\u001b[0m  0.0905\n","     55        \u001b[36m0.0108\u001b[0m        \u001b[32m4.0958\u001b[0m  0.0865\n","     56        \u001b[36m0.0102\u001b[0m        \u001b[32m4.0940\u001b[0m  0.0904\n","     57        \u001b[36m0.0097\u001b[0m        \u001b[32m4.0923\u001b[0m  0.0955\n","     58        \u001b[36m0.0092\u001b[0m        \u001b[32m4.0907\u001b[0m  0.1123\n","     59        \u001b[36m0.0087\u001b[0m        \u001b[32m4.0892\u001b[0m  0.1429\n","     60        \u001b[36m0.0083\u001b[0m        \u001b[32m4.0878\u001b[0m  0.1107\n","     61        \u001b[36m0.0079\u001b[0m        \u001b[32m4.0864\u001b[0m  0.1102\n","     62        \u001b[36m0.0075\u001b[0m        \u001b[32m4.0851\u001b[0m  0.1100\n","     63        \u001b[36m0.0071\u001b[0m        \u001b[32m4.0839\u001b[0m  0.1094\n","     64        \u001b[36m0.0068\u001b[0m        \u001b[32m4.0827\u001b[0m  0.1084\n","     65        \u001b[36m0.0065\u001b[0m        \u001b[32m4.0816\u001b[0m  0.1081\n","     66        \u001b[36m0.0062\u001b[0m        \u001b[32m4.0805\u001b[0m  0.1037\n","     67        \u001b[36m0.0059\u001b[0m        \u001b[32m4.0795\u001b[0m  0.1241\n","     68        \u001b[36m0.0056\u001b[0m        \u001b[32m4.0785\u001b[0m  0.1180\n","     69        \u001b[36m0.0054\u001b[0m        \u001b[32m4.0776\u001b[0m  0.1032\n","     70        \u001b[36m0.0051\u001b[0m        \u001b[32m4.0767\u001b[0m  0.0921\n","     71        \u001b[36m0.0049\u001b[0m        \u001b[32m4.0759\u001b[0m  0.0942\n","     72        \u001b[36m0.0047\u001b[0m        \u001b[32m4.0752\u001b[0m  0.0946\n","     73        \u001b[36m0.0045\u001b[0m        \u001b[32m4.0744\u001b[0m  0.1000\n","     74        \u001b[36m0.0043\u001b[0m        \u001b[32m4.0737\u001b[0m  0.0927\n","     75        \u001b[36m0.0041\u001b[0m        \u001b[32m4.0730\u001b[0m  0.0973\n","     76        \u001b[36m0.0039\u001b[0m        \u001b[32m4.0723\u001b[0m  0.1063\n","     77        \u001b[36m0.0038\u001b[0m        \u001b[32m4.0717\u001b[0m  0.0930\n","     78        \u001b[36m0.0036\u001b[0m        \u001b[32m4.0710\u001b[0m  0.0993\n","     79        \u001b[36m0.0035\u001b[0m        \u001b[32m4.0705\u001b[0m  0.1302\n","     80        \u001b[36m0.0033\u001b[0m        \u001b[32m4.0699\u001b[0m  0.1096\n","     81        \u001b[36m0.0032\u001b[0m        \u001b[32m4.0693\u001b[0m  0.1054\n","     82        \u001b[36m0.0031\u001b[0m        \u001b[32m4.0688\u001b[0m  0.1040\n","     83        \u001b[36m0.0029\u001b[0m        \u001b[32m4.0683\u001b[0m  0.1035\n","     84        \u001b[36m0.0028\u001b[0m        \u001b[32m4.0679\u001b[0m  0.0945\n","     85        \u001b[36m0.0027\u001b[0m        \u001b[32m4.0674\u001b[0m  0.0958\n","     86        \u001b[36m0.0026\u001b[0m        \u001b[32m4.0670\u001b[0m  0.0875\n","     87        \u001b[36m0.0025\u001b[0m        \u001b[32m4.0666\u001b[0m  0.0953\n","     88        \u001b[36m0.0024\u001b[0m        \u001b[32m4.0662\u001b[0m  0.0905\n","     89        \u001b[36m0.0023\u001b[0m        \u001b[32m4.0658\u001b[0m  0.0898\n","     90        \u001b[36m0.0022\u001b[0m        \u001b[32m4.0654\u001b[0m  0.0939\n","     91        \u001b[36m0.0021\u001b[0m        \u001b[32m4.0651\u001b[0m  0.0947\n","     92        \u001b[36m0.0021\u001b[0m        \u001b[32m4.0647\u001b[0m  0.1149\n","     93        \u001b[36m0.0020\u001b[0m        \u001b[32m4.0644\u001b[0m  0.1101\n","     94        \u001b[36m0.0019\u001b[0m        \u001b[32m4.0641\u001b[0m  0.0951\n","     95        \u001b[36m0.0018\u001b[0m        \u001b[32m4.0638\u001b[0m  0.0896\n","     96        \u001b[36m0.0018\u001b[0m        \u001b[32m4.0635\u001b[0m  0.0895\n","     97        \u001b[36m0.0017\u001b[0m        \u001b[32m4.0632\u001b[0m  0.0895\n","     98        \u001b[36m0.0016\u001b[0m        \u001b[32m4.0629\u001b[0m  0.0946\n","     99        \u001b[36m0.0016\u001b[0m        \u001b[32m4.0627\u001b[0m  0.0963\n","    100        \u001b[36m0.0015\u001b[0m        \u001b[32m4.0624\u001b[0m  0.0992\n","    101        \u001b[36m0.0015\u001b[0m        \u001b[32m4.0622\u001b[0m  0.0901\n","    102        \u001b[36m0.0014\u001b[0m        \u001b[32m4.0619\u001b[0m  0.0891\n","    103        \u001b[36m0.0014\u001b[0m        \u001b[32m4.0617\u001b[0m  0.0889\n","    104        \u001b[36m0.0013\u001b[0m        \u001b[32m4.0615\u001b[0m  0.0882\n","    105        \u001b[36m0.0013\u001b[0m        \u001b[32m4.0613\u001b[0m  0.0900\n","    106        \u001b[36m0.0012\u001b[0m        \u001b[32m4.0611\u001b[0m  0.0953\n","    107        \u001b[36m0.0012\u001b[0m        \u001b[32m4.0609\u001b[0m  0.1197\n","    108        \u001b[36m0.0012\u001b[0m        \u001b[32m4.0607\u001b[0m  0.0950\n","    109        \u001b[36m0.0011\u001b[0m        \u001b[32m4.0605\u001b[0m  0.0893\n","    110        \u001b[36m0.0011\u001b[0m        \u001b[32m4.0604\u001b[0m  0.0896\n","    111        \u001b[36m0.0010\u001b[0m        \u001b[32m4.0602\u001b[0m  0.0888\n","    112        \u001b[36m0.0010\u001b[0m        \u001b[32m4.0600\u001b[0m  0.0894\n","    113        \u001b[36m0.0010\u001b[0m        \u001b[32m4.0599\u001b[0m  0.0977\n","    114        \u001b[36m0.0009\u001b[0m        \u001b[32m4.0597\u001b[0m  0.1220\n","    115        \u001b[36m0.0009\u001b[0m        \u001b[32m4.0596\u001b[0m  0.1098\n","    116        \u001b[36m0.0009\u001b[0m        \u001b[32m4.0594\u001b[0m  0.1099\n","    117        \u001b[36m0.0009\u001b[0m        \u001b[32m4.0593\u001b[0m  0.1077\n","    118        \u001b[36m0.0008\u001b[0m        \u001b[32m4.0591\u001b[0m  0.1178\n","    119        \u001b[36m0.0008\u001b[0m        \u001b[32m4.0590\u001b[0m  0.1178\n","    120        \u001b[36m0.0008\u001b[0m        \u001b[32m4.0589\u001b[0m  0.1010\n","    121        \u001b[36m0.0008\u001b[0m        \u001b[32m4.0588\u001b[0m  0.1109\n","    122        \u001b[36m0.0007\u001b[0m        \u001b[32m4.0587\u001b[0m  0.1098\n","    123        \u001b[36m0.0007\u001b[0m        \u001b[32m4.0586\u001b[0m  0.1088\n","    124        \u001b[36m0.0007\u001b[0m        \u001b[32m4.0584\u001b[0m  0.1061\n","    125        \u001b[36m0.0007\u001b[0m        \u001b[32m4.0583\u001b[0m  0.1020\n","    126        \u001b[36m0.0007\u001b[0m        \u001b[32m4.0582\u001b[0m  0.1080\n","    127        \u001b[36m0.0006\u001b[0m        \u001b[32m4.0581\u001b[0m  0.0969\n","    128        \u001b[36m0.0006\u001b[0m        \u001b[32m4.0580\u001b[0m  0.1014\n","    129        \u001b[36m0.0006\u001b[0m        \u001b[32m4.0579\u001b[0m  0.1277\n","    130        \u001b[36m0.0006\u001b[0m        \u001b[32m4.0579\u001b[0m  0.1126\n","    131        \u001b[36m0.0006\u001b[0m        \u001b[32m4.0578\u001b[0m  0.1010\n","    132        \u001b[36m0.0005\u001b[0m        \u001b[32m4.0577\u001b[0m  0.1059\n","    133        \u001b[36m0.0005\u001b[0m        \u001b[32m4.0576\u001b[0m  0.1041\n","    134        \u001b[36m0.0005\u001b[0m        \u001b[32m4.0576\u001b[0m  0.1006\n","    135        \u001b[36m0.0005\u001b[0m        \u001b[32m4.0575\u001b[0m  0.1015\n","    136        \u001b[36m0.0005\u001b[0m        \u001b[32m4.0574\u001b[0m  0.0978\n","    137        \u001b[36m0.0005\u001b[0m        \u001b[32m4.0573\u001b[0m  0.0922\n","    138        \u001b[36m0.0005\u001b[0m        \u001b[32m4.0573\u001b[0m  0.0899\n","    139        \u001b[36m0.0004\u001b[0m        \u001b[32m4.0572\u001b[0m  0.0891\n","    140        \u001b[36m0.0004\u001b[0m        \u001b[32m4.0571\u001b[0m  0.0874\n","    141        \u001b[36m0.0004\u001b[0m        \u001b[32m4.0571\u001b[0m  0.0901\n","    142        \u001b[36m0.0004\u001b[0m        \u001b[32m4.0570\u001b[0m  0.0947\n","    143        \u001b[36m0.0004\u001b[0m        \u001b[32m4.0569\u001b[0m  0.1528\n","    144        \u001b[36m0.0004\u001b[0m        \u001b[32m4.0569\u001b[0m  0.1503\n","    145        \u001b[36m0.0004\u001b[0m        \u001b[32m4.0568\u001b[0m  0.1371\n","    146        \u001b[36m0.0004\u001b[0m        \u001b[32m4.0568\u001b[0m  0.1107\n","    147        \u001b[36m0.0004\u001b[0m        \u001b[32m4.0567\u001b[0m  0.1046\n","    148        \u001b[36m0.0004\u001b[0m        \u001b[32m4.0567\u001b[0m  0.1012\n","    149        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0566\u001b[0m  0.0952\n","    150        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0566\u001b[0m  0.0968\n","    151        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0566\u001b[0m  0.0936\n","    152        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0565\u001b[0m  0.0937\n","    153        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0565\u001b[0m  0.1125\n","    154        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0564\u001b[0m  0.1102\n","    155        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0564\u001b[0m  0.1652\n","    156        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0564\u001b[0m  0.1321\n","    157        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0563\u001b[0m  0.0983\n","    158        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0563\u001b[0m  0.0935\n","    159        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0562\u001b[0m  0.0946\n","    160        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0562\u001b[0m  0.0895\n","    161        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0562\u001b[0m  0.0917\n","    162        \u001b[36m0.0003\u001b[0m        \u001b[32m4.0561\u001b[0m  0.1106\n","    163        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0561\u001b[0m  0.0936\n","    164        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0561\u001b[0m  0.0897\n","    165        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0561\u001b[0m  0.0897\n","    166        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0560\u001b[0m  0.0923\n","    167        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0560\u001b[0m  0.0928\n","    168        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0560\u001b[0m  0.1026\n","    169        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0560\u001b[0m  0.1079\n","    170        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0559\u001b[0m  0.1031\n","    171        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0559\u001b[0m  0.0973\n","    172        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0559\u001b[0m  0.0984\n","    173        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0559\u001b[0m  0.1513\n","    174        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0558\u001b[0m  0.1763\n","    175        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0558\u001b[0m  0.1128\n","    176        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0558\u001b[0m  0.0975\n","    177        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0558\u001b[0m  0.1066\n","    178        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0558\u001b[0m  0.0984\n","    179        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0557\u001b[0m  0.0977\n","    180        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0557\u001b[0m  0.1013\n","    181        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0557\u001b[0m  0.1144\n","    182        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0557\u001b[0m  0.1895\n","    183        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0557\u001b[0m  0.1438\n","    184        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0557\u001b[0m  0.1269\n","    185        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0556\u001b[0m  0.1130\n","    186        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0556\u001b[0m  0.1052\n","    187        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0556\u001b[0m  0.1021\n","    188        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0556\u001b[0m  0.0920\n","    189        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0556\u001b[0m  0.0937\n","    190        \u001b[36m0.0002\u001b[0m        \u001b[32m4.0556\u001b[0m  0.0975\n","    191        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0556\u001b[0m  0.0934\n","    192        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0556\u001b[0m  0.0914\n","    193        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0555\u001b[0m  0.0944\n","    194        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0555\u001b[0m  0.0936\n","    195        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0555\u001b[0m  0.0901\n","    196        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0555\u001b[0m  0.0897\n","    197        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0555\u001b[0m  0.0920\n","    198        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0555\u001b[0m  0.0898\n","    199        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0555\u001b[0m  0.0904\n","    200        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0555\u001b[0m  0.0947\n","    201        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0555\u001b[0m  0.0989\n","    202        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0884\n","    203        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0894\n","    204        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.1075\n","    205        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0910\n","    206        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0903\n","    207        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0890\n","    208        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0892\n","    209        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0903\n","    210        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0976\n","    211        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.1080\n","    212        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.1079\n","    213        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0968\n","    214        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0967\n","    215        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0554\u001b[0m  0.0946\n","    216        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0901\n","    217        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0911\n","    218        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0933\n","    219        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0920\n","    220        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.1090\n","    221        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.1103\n","    222        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0931\n","    223        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0912\n","    224        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0894\n","    225        \u001b[36m0.0001\u001b[0m        4.0553  0.1089\n","    226        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0978\n","    227        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0965\n","    228        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0929\n","    229        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0876\n","    230        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0920\n","    231        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0957\n","    232        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0907\n","    233        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0918\n","    234        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0908\n","    235        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0930\n","    236        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0908\n","    237        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0942\n","    238        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.0896\n","    239        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.1170\n","    240        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0553\u001b[0m  0.1041\n","    241        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0909\n","    242        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0918\n","    243        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0879\n","    244        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0902\n","    245        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0964\n","    246        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0920\n","    247        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0934\n","    248        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0909\n","    249        \u001b[36m0.0001\u001b[0m        4.0552  0.0919\n","    250        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0953\n","    251        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1135\n","    252        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0908\n","    253        \u001b[36m0.0001\u001b[0m        4.0552  0.0891\n","    254        \u001b[36m0.0001\u001b[0m        4.0552  0.0912\n","    255        \u001b[36m0.0001\u001b[0m        4.0552  0.0934\n","    256        \u001b[36m0.0001\u001b[0m        4.0552  0.0914\n","    257        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0928\n","    258        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0907\n","    259        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0928\n","    260        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1526\n","    261        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1500\n","    262        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1426\n","    263        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1041\n","    264        \u001b[36m0.0001\u001b[0m        4.0552  0.1016\n","    265        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1017\n","    266        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1588\n","    267        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1563\n","    268        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1102\n","    269        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0973\n","    270        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0962\n","    271        \u001b[36m0.0001\u001b[0m        4.0552  0.1524\n","    272        \u001b[36m0.0001\u001b[0m        4.0552  0.1808\n","    273        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1333\n","    274        \u001b[36m0.0001\u001b[0m        4.0552  0.1023\n","    275        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0940\n","    276        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1200\n","    277        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1639\n","    278        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1247\n","    279        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0932\n","    280        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1060\n","    281        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0993\n","    282        \u001b[36m0.0001\u001b[0m        4.0552  0.0904\n","    283        \u001b[36m0.0001\u001b[0m        4.0552  0.0942\n","    284        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0943\n","    285        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0919\n","    286        \u001b[36m0.0001\u001b[0m        4.0552  0.0914\n","    287        \u001b[36m0.0001\u001b[0m        4.0552  0.0928\n","    288        \u001b[36m0.0001\u001b[0m        4.0552  0.0947\n","    289        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0978\n","    290        \u001b[36m0.0001\u001b[0m        4.0552  0.0996\n","    291        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1113\n","    292        \u001b[36m0.0001\u001b[0m        4.0552  0.1251\n","    293        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.1022\n","    294        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0949\n","    295        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0913\n","    296        \u001b[36m0.0001\u001b[0m        4.0552  0.0956\n","    297        \u001b[36m0.0001\u001b[0m        4.0552  0.0896\n","    298        \u001b[36m0.0001\u001b[0m        4.0552  0.0913\n","    299        \u001b[36m0.0001\u001b[0m        \u001b[32m4.0552\u001b[0m  0.0944\n","    300        \u001b[36m0.0001\u001b[0m        4.0552  0.1311\n"]}],"source":["# TODO\n","cols = ['construct','task']\n","\n","# create X_c (co-occurrence matrix)\n","COOC = PUBMED.pipe(co_occurrence_matrix, jaccard_coefficient=True, groupby_category=True)\n","X = np.vstack([COOC[c].astype('category').cat.codes for c in cols]).T\n","y = COOC[['jaccard_coefficient']].values\n","\n","# TODO drop 0 probabilities from X\n","# TODO n_embeddings should be a hyper parameter (use Ax to optimize)\n","\n","# model = MFNet(n_tasks, n_constructs, 7)\n","# model.fit(torch.tensor(X, dtype=torch.int), torch.tensor(y, dtype=torch.float))\n","\n","X = torch.tensor(X, dtype=torch.int)\n","y = torch.tensor(y, dtype=torch.float)\n","\n","net = NeuralNetRegressor(\n","    MFNet(n_tasks, n_constructs, 7),\n","    max_epochs=1000,\n","    lr=0.1,\n","    # Shuffle training data on each epoch\n","    iterator_train__shuffle=True,\n","    callbacks=[TensorBoard(writer=SummaryWriter())]\n",")\n","\n","net.fit(X, y)\n","y_proba = net.predict_proba(X)\n","\n","# %reload_ext tensorboard\n","# %tensorboard --logdir=runs/"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(-0.1276)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["y_pred = net.predict(X)\n","(y - y_pred).mean()"]}],"metadata":{"interpreter":{"hash":"5ddcf14c786c671500c086f61f0b66d0417d6c58ff12753e346e191a84f72b84"},"kernelspec":{"display_name":"Python 3.9.4 64-bit ('py3': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
