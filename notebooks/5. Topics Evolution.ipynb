{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('py3': conda)"
  },
  "interpreter": {
   "hash": "5ddcf14c786c671500c086f61f0b66d0417d6c58ff12753e346e191a84f72b84"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Topics model evolution over time\n",
    "\n",
    "This notebook demonstrate evolution of topic models over time. The following steps are performed on the publication abstracts:\n",
    "\n",
    "- Preprocessing the text, such as removing stop words, word stemming, lemmatize, and n-gram phrase detection.\n",
    "- Use BERT to encode documents into embeddings.\n",
    "- dimentionality reduction of embeddings using UMAP.\n",
    "- Hierarchical DBSCAN to form clusters of embeddings.\n",
    "- Assign scores to words with regard to the clusters.\n",
    "- Extract most coheret topics (c-TD-IDF algorithm).\n",
    "- Fine-tune clusters and topics at different publicationn dates to model topic evolution.\n",
    "\n",
    "**c-TD-IDF**: $c\\_td\\_idf = {t_i \\over w_i} \\times log{m \\over {\\Sigma_j^n t_j}}$\n",
    "\n",
    "\n",
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim.models.phrases import ENGLISH_CONNECTOR_WORDS\n",
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "CUSTOM_STOP_WORDS = ['study', 'task', 'test']\n",
    "PREPROCESSED_ABSTRACTS_FILE = Path('data/pubmed/tests_preprocessed.csv')"
   ]
  },
  {
   "source": [
    "## Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Note: run this to download the SpaCy model: `python -m spacy download en_core_web_sm`\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def preprocess(texts: list[str], corpus_name: str) -> list[str]:\n",
    "  \"\"\"Opinionated preprocessing pipeline.\n",
    "\n",
    "  Args:\n",
    "      texts (list[str]): list of texts, each item is one text document.\n",
    "      corpus_name (str): Name of the corpus\n",
    "\n",
    "  Returns:\n",
    "      list[str]: preprocessed documents\n",
    "  \"\"\"\n",
    "  # DEBUG standard preprocessing pipeline\n",
    "  # docs = \\\n",
    "  #   texts['abstract'].progress_apply(lambda abstract: gensim.parsing.preprocess_string(abstract)).to_list()\n",
    "\n",
    "  print(f'Preprocessing {corpus_name}...', file=sys.stderr)\n",
    "\n",
    "  # additional stop words\n",
    "  for stop_word in CUSTOM_STOP_WORDS:\n",
    "    lexeme = nlp.vocab[stop_word]\n",
    "    lexeme.is_stop = True\n",
    "\n",
    "  # flake8: noqa: W503\n",
    "  def _clean(doc):\n",
    "    cleaned = []\n",
    "    for token in doc:\n",
    "      if (not token.is_punct\n",
    "          and token.is_alpha\n",
    "          and not token.is_stop\n",
    "          and not token.like_num\n",
    "          and not token.is_space):\n",
    "        cleaned.append(token.lemma_.lower().strip())\n",
    "    return cleaned\n",
    "\n",
    "  docs = tqdm([_clean(txt) for txt in nlp.pipe(texts)], desc='Cleaning abstracts')\n",
    "\n",
    "  # bigram\n",
    "  ngram_phrases = gensim.models.Phrases(docs, connector_words=ENGLISH_CONNECTOR_WORDS) #, scoring='npmi')\n",
    "\n",
    "  # there are cases that a test or construct contains 4 terms; a heuristic for n-grams is to count spaces in the corpus_name\n",
    "  for _ in range(max(1, 2 + corpus_name.count(' '))):\n",
    "    ngram_phrases = gensim.models.Phrases(ngram_phrases[docs], connector_words=ENGLISH_CONNECTOR_WORDS) #, scoring='npmi')\n",
    "\n",
    "  ngram = gensim.models.phrases.Phraser(ngram_phrases)\n",
    "  docs = [' '.join(doc) for doc in ngram[docs]]\n",
    "  # FIXME filter ngram stop words: docs = [[w for w in doc if w not in my_stop_words] for doc in docs]\n",
    "\n",
    "  return docs\n"
   ]
  },
  {
   "source": [
    "Now load PubMed abstracts ad preprocess them. This takes a few minutes to run and preprocessed abstracts will be stored in `data/pubmed/tests_preprocessed.csv`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if PREPROCESSED_ABSTRACTS_FILE.exists():\n",
    "    # load from cached csv\n",
    "    df = pd.read_csv(PREPROCESSED_ABSTRACTS_FILE)\n",
    "else:\n",
    "    # if preprocessed abstracts are not already available\n",
    "    csv_files = Path('data/pubmed/tests').glob('*.csv')\n",
    "\n",
    "    corpora = []\n",
    "\n",
    "    for csv_file in tqdm(csv_files, desc='Reading CSV files', unit=' files'):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df['corpus_name'] = csv_file.stem\n",
    "        corpora.append(df)\n",
    "\n",
    "    df = pd.concat(corpora, axis=0)\n",
    "    df['abstract'].fillna(df['title'], inplace=True)\n",
    "\n",
    "    df['preprocessed_abstract'] = df.groupby('corpus_name')['abstract'].transform(\n",
    "        lambda grp: preprocess(grp.to_list(), grp.name)\n",
    "    )\n",
    "\n",
    "    # store the preprocessed abstracts as a csv file.\n",
    "    df.to_csv('data/pubmed/tests_preprocessed.csv')\n",
    "\n",
    "print('Done! Feel free to move on to the next cell.')"
   ]
  },
  {
   "source": [
    "As a visual check, a word cloud can quickly visualize the whole preprocessed corpus."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "combined_text = df['preprocessed_abstract'].str.cat(sep=' ')\n",
    "\n",
    "cloud = WordCloud(width=500,height=500,background_color ='white').generate(combined_text)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(cloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "## Overall topics (time-independent model)\n",
    "\n",
    "In this section, we fit a topic model on all the PubMed cognitive task abstracts given which task the text belongs to."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_topic_model(docs, corpus_name):\n",
    "    \"\"\"Fit a topic model to the docs and return the fitted model, and the topics.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f'fitting topics for {corpus_name}...', file=sys.stderr)\n",
    "\n",
    "    topic_model = BERTopic(verbose=True)\n",
    "    topics, _ = topic_model.fit_transform(docs)\n",
    "    return topic_model, topics\n",
    "\n",
    "models = df.groupby('corpus_name').apply(\n",
    "    lambda grp: fit_topic_model(grp['preprocessed_abstract'].to_list(), grp.name)\n",
    ")\n",
    "\n",
    "# topic_model.get_topic_info()\n",
    "\n",
    "# DEBUG\n",
    "# topic_model.get_topics()\n",
    "# topic_model.get_topic(0)"
   ]
  },
  {
   "source": [
    "## Topics evolution over the span of the years (time-dependent model)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_over_time = topic_model.topics_over_time(docs, topics, df['year'], datetime_format=\"%b\")\n",
    "topic_model.visualize_topics_over_time(topics_over_time, top_n_topics=20)"
   ]
  }
 ]
}